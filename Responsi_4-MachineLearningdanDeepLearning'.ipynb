{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a8b1593-cd4f-4f9a-bce9-dc51b3095de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy\n",
    "import pickle\n",
    "import pefile\n",
    "import sklearn.ensemble as ek\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import joblib\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8626db02-a29f-4562-b627-6a2aaa2416cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Dataset 1\n",
    "dataset1 = pd.read_csv(\"C:\\\\Data Raihan\\Perkuliahan Semester 8\\\\SKC\\\\Dataset\\\\Cyber Security Attacks\\\\cybersecurity_attacks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "391fcd0e-4ddb-4258-b96a-84f9508c4814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Timestamp', 'Source IP Address', 'Destination IP Address',\n",
       "       'Source Port', 'Destination Port', 'Protocol', 'Packet Length',\n",
       "       'Packet Type', 'Traffic Type', 'Payload Data', 'Malware Indicators',\n",
       "       'Anomaly Scores', 'Alerts/Warnings', 'Attack Type', 'Attack Signature',\n",
       "       'Action Taken', 'Severity Level', 'User Information',\n",
       "       'Device Information', 'Network Segment', 'Geo-location Data',\n",
       "       'Proxy Information', 'Firewall Logs', 'IDS/IPS Alerts', 'Log Source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan nama Kolom yang ada pada dataset 1\n",
    "dataset1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "967ce6e3-a64b-44d8-a0f0-b0d99e4004e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Timestamp               40000 non-null  object \n",
      " 1   Source IP Address       40000 non-null  object \n",
      " 2   Destination IP Address  40000 non-null  object \n",
      " 3   Source Port             40000 non-null  int64  \n",
      " 4   Destination Port        40000 non-null  int64  \n",
      " 5   Protocol                40000 non-null  object \n",
      " 6   Packet Length           40000 non-null  int64  \n",
      " 7   Packet Type             40000 non-null  object \n",
      " 8   Traffic Type            40000 non-null  object \n",
      " 9   Payload Data            40000 non-null  object \n",
      " 10  Malware Indicators      20000 non-null  object \n",
      " 11  Anomaly Scores          40000 non-null  float64\n",
      " 12  Alerts/Warnings         19933 non-null  object \n",
      " 13  Attack Type             40000 non-null  object \n",
      " 14  Attack Signature        40000 non-null  object \n",
      " 15  Action Taken            40000 non-null  object \n",
      " 16  Severity Level          40000 non-null  object \n",
      " 17  User Information        40000 non-null  object \n",
      " 18  Device Information      40000 non-null  object \n",
      " 19  Network Segment         40000 non-null  object \n",
      " 20  Geo-location Data       40000 non-null  object \n",
      " 21  Proxy Information       20149 non-null  object \n",
      " 22  Firewall Logs           20039 non-null  object \n",
      " 23  IDS/IPS Alerts          19950 non-null  object \n",
      " 24  Log Source              40000 non-null  object \n",
      "dtypes: float64(1), int64(3), object(21)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan fitur yang ada pada dataset 1\n",
    "dataset1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81f3c59e-4fca-4b74-ab12-0ff0f9fcec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection\n",
    "X = dataset1.drop(['Payload Data','Alerts/Warnings','Proxy Information', 'Malware Indicators', 'Firewall Logs', 'IDS/IPS Alerts'], axis=1).select_dtypes(include=['float64', 'int64']).values\n",
    "# Target variable\n",
    "y = dataset1['Malware Indicators'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "497394ef-53e8-484a-96b4-d1c8856c860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengisi value yang null dengan mean dari feature tersebut\n",
    "dataset1['Malware Indicators'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c83cb88b-ad37-45e9-8244-5cd6c9b63e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Fitting and choosing the important variables\n",
    "extratrees = ek.ExtraTreesClassifier().fit(X,y)\n",
    "model = SelectFromModel(extratrees, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "nbfeatures = X_new.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73303a8f-3403-42f4-b504-8451d9907396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ubah label menjadi format numerik\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0ac0a07-a350-48ba-9bbd-256e88e8b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data (70% - training and 30% - testing)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y ,test_size=0.29, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34f0af47-357b-4220-91de-3b99842bde06",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "index = numpy.argsort(extratrees.feature_importances_)[::-1][:nbfeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40365384-8e38-437c-b9c7-511f7df6956c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. feature Destination IP Address (0.250872)\n",
      "2. feature Source Port (0.250438)\n",
      "3. feature Protocol (0.250289)\n"
     ]
    }
   ],
   "source": [
    "#All the required features\n",
    "for f in range(nbfeatures):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, dataset1.columns[2+index[f]], extratrees.feature_importances_[index[f]]))\n",
    "    features.append(dataset1.columns[2+f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3a2d0b7-1c31-44b4-93f4-a61cbfbaefe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [(\"Naive Bayes\", GaussianNB()),\n",
    "              (\"DecisionTree\", DecisionTreeClassifier(max_depth=10)),\n",
    "              (\"RandomForest\", ek.RandomForestClassifier(n_estimators=50))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7136bbf9-1e0d-4386-b06f-1e720e28d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Deep Neural Network (DNN) model\n",
    "model_dnn = Sequential()\n",
    "model_dnn.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "model_dnn.add(Dense(64, activation='relu'))\n",
    "model_dnn.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ad628f9-78b8-45e3-829e-f7edab60ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train and X_test are your input data arrays\n",
    "X_train_reshaped = np.expand_dims(X_train, axis=-1)\n",
    "X_test_reshaped = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "# Define the Convolutional Neural Network (CNN) model\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Flatten(input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a31aa7dd-b636-4369-a0c9-150874fce3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing which Classifier will give better result\n",
    "model = { \n",
    "    \"DecisionTree\": DecisionTreeClassifier(max_depth=10),\n",
    "    \"RandomForest\": ek.RandomForestClassifier(n_estimators=50),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=0, max_iter=10000),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"MLP\": MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1),\n",
    "    \"Stochastic Gradient Descent\": SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=10000),\n",
    "    \"ADA Boost\": AdaBoostClassifier(n_estimators=100),\n",
    "    \"Stack Ensamble\": StackingClassifier(estimators=estimators, final_estimator=LogisticRegression()),\n",
    "    \"Deep Neural Network\": model_dnn,\n",
    "    \"Convolutional Neural Network\": model_cnn\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1074c30f-8ac7-45d0-9184-56c8b8ea3ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree : Training Score: 0.5363732394366197, Testing Score: 0.4921551724137931\n",
      "Total Training Time: 0.12833356857299805 seconds\n",
      "Total Testing Time: 0.0010004043579101562 seconds\n",
      "RandomForest : Training Score: 1.0, Testing Score: 0.5013793103448276\n",
      "Total Training Time: 5.223153352737427 seconds\n",
      "Total Testing Time: 0.12387251853942871 seconds\n",
      "Logistic Regression : Training Score: 0.5065140845070423, Testing Score: 0.4912068965517241\n",
      "Total Training Time: 0.025673389434814453 seconds\n",
      "Total Testing Time: 0.0010004043579101562 seconds\n",
      "Naive Bayes : Training Score: 0.5089084507042253, Testing Score: 0.4961206896551724\n",
      "Total Training Time: 0.0035390853881835938 seconds\n",
      "Total Testing Time: 0.0015873908996582031 seconds\n",
      "MLP : Training Score: 0.5, Testing Score: 0.5\n",
      "Total Training Time: 0.8203692436218262 seconds\n",
      "Total Testing Time: 0.002259492874145508 seconds\n",
      "Stochastic Gradient Descent : Training Score: 0.5011267605633802, Testing Score: 0.5017241379310344\n",
      "Total Training Time: 0.3641471862792969 seconds\n",
      "Total Testing Time: 0.0010004043579101562 seconds\n",
      "ADA Boost : Training Score: 0.5332394366197183, Testing Score: 0.5010344827586207\n",
      "Total Training Time: 2.107081174850464 seconds\n",
      "Total Testing Time: 0.07590818405151367 seconds\n",
      "Stack Ensamble : Training Score: 0.06348591549295775, Testing Score: 0.4954310344827586\n",
      "Total Training Time: 27.43778944015503 seconds\n",
      "Total Testing Time: 0.12043118476867676 seconds\n",
      "Epoch 1/20\n",
      "888/888 [==============================] - 1s 759us/step - loss: 84.3896 - accuracy: 0.5036\n",
      "Epoch 2/20\n",
      "888/888 [==============================] - 1s 749us/step - loss: 44.1774 - accuracy: 0.4976\n",
      "Epoch 3/20\n",
      "888/888 [==============================] - 1s 751us/step - loss: 35.4100 - accuracy: 0.5035\n",
      "Epoch 4/20\n",
      "888/888 [==============================] - 1s 757us/step - loss: 25.4660 - accuracy: 0.5017\n",
      "Epoch 5/20\n",
      "888/888 [==============================] - 1s 812us/step - loss: 24.2345 - accuracy: 0.4988\n",
      "Epoch 6/20\n",
      "888/888 [==============================] - 1s 821us/step - loss: 18.5667 - accuracy: 0.4997\n",
      "Epoch 7/20\n",
      "888/888 [==============================] - 1s 833us/step - loss: 16.7981 - accuracy: 0.5037\n",
      "Epoch 8/20\n",
      "888/888 [==============================] - 1s 806us/step - loss: 14.5741 - accuracy: 0.5012\n",
      "Epoch 9/20\n",
      "888/888 [==============================] - 1s 962us/step - loss: 10.6498 - accuracy: 0.5033\n",
      "Epoch 10/20\n",
      "888/888 [==============================] - 1s 813us/step - loss: 11.6489 - accuracy: 0.5015\n",
      "Epoch 11/20\n",
      "888/888 [==============================] - 1s 780us/step - loss: 8.1775 - accuracy: 0.5039\n",
      "Epoch 12/20\n",
      "888/888 [==============================] - 1s 801us/step - loss: 8.1889 - accuracy: 0.5016\n",
      "Epoch 13/20\n",
      "888/888 [==============================] - 1s 813us/step - loss: 6.5755 - accuracy: 0.5002\n",
      "Epoch 14/20\n",
      "888/888 [==============================] - 1s 808us/step - loss: 5.9554 - accuracy: 0.5013\n",
      "Epoch 15/20\n",
      "888/888 [==============================] - 1s 847us/step - loss: 5.1718 - accuracy: 0.4932\n",
      "Epoch 16/20\n",
      "888/888 [==============================] - 1s 823us/step - loss: 3.7158 - accuracy: 0.4977\n",
      "Epoch 17/20\n",
      "888/888 [==============================] - 1s 776us/step - loss: 3.3778 - accuracy: 0.5030\n",
      "Epoch 18/20\n",
      "888/888 [==============================] - 1s 774us/step - loss: 2.6967 - accuracy: 0.5003\n",
      "Epoch 19/20\n",
      "888/888 [==============================] - 1s 841us/step - loss: 2.7499 - accuracy: 0.5030\n",
      "Epoch 20/20\n",
      "888/888 [==============================] - 1s 759us/step - loss: 2.5539 - accuracy: 0.4985\n",
      "Deep Neural Network : Training Score: 0.5002464652061462, Testing Score: 0.4997413754463196\n",
      "Total Training Time: 14.849382400512695 seconds\n",
      "Total Testing Time: 0.0 seconds\n",
      "Epoch 1/20\n",
      "888/888 [==============================] - 1s 579us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Epoch 2/20\n",
      "888/888 [==============================] - 1s 573us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Epoch 3/20\n",
      "888/888 [==============================] - 1s 568us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Epoch 4/20\n",
      "888/888 [==============================] - 1s 576us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Epoch 5/20\n",
      "888/888 [==============================] - 1s 574us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Epoch 6/20\n",
      "888/888 [==============================] - 1s 580us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Epoch 7/20\n",
      "888/888 [==============================] - 1s 579us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Epoch 8/20\n",
      "888/888 [==============================] - 1s 576us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Epoch 9/20\n",
      "888/888 [==============================] - 1s 568us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Epoch 10/20\n",
      "888/888 [==============================] - 1s 570us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Epoch 11/20\n",
      "888/888 [==============================] - 1s 586us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Epoch 12/20\n",
      "888/888 [==============================] - 1s 571us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Epoch 13/20\n",
      "888/888 [==============================] - 1s 594us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Epoch 14/20\n",
      "888/888 [==============================] - 1s 573us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Epoch 15/20\n",
      "888/888 [==============================] - 1s 576us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Epoch 16/20\n",
      "888/888 [==============================] - 1s 575us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Epoch 17/20\n",
      "888/888 [==============================] - 1s 577us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Epoch 18/20\n",
      "888/888 [==============================] - 1s 574us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Epoch 19/20\n",
      "888/888 [==============================] - 1s 587us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Epoch 20/20\n",
      "888/888 [==============================] - 1s 588us/step - loss: 7.6038 - accuracy: 0.4994\n",
      "Convolutional Neural Network : Training Score: 0.499436616897583, Testing Score: 0.5011206865310669\n",
      "Total Training Time: 10.442614078521729 seconds\n",
      "Total Testing Time: 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for algo in model:\n",
    "    if algo == \"Deep Neural Network\" or algo == \"Convolutional Neural Network\":\n",
    "        clf = model[algo]\n",
    "        # Waktu awal training\n",
    "        start_time = time.time()\n",
    "        clf.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        clf.fit(X_train, y_train , epochs=20)\n",
    "        # Waktu akhir training\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Evaluate the model\n",
    "        _, score_train = clf.evaluate(X_train, y_train, verbose=0)\n",
    "        _, score_test = clf.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "        # Waktu awal testing\n",
    "        start_time_test = time.time()\n",
    "\n",
    "        # Waktu akhir testing\n",
    "        end_time_test = time.time()\n",
    "\n",
    "        print(\"%s : Training Score: %s, Testing Score: %s\" % (algo, score_train, score_test))\n",
    "\n",
    "        # Menghitung total waktu training\n",
    "        training_time = end_time - start_time\n",
    "        print(\"Total Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "        # Menghitung total waktu testing\n",
    "        testing_time = end_time_test - start_time_test\n",
    "        print(\"Total Testing Time:\", testing_time, \"seconds\")\n",
    "\n",
    "        results[algo] = (score_train, score_test, training_time, testing_time)\n",
    "    else:\n",
    "        clf = model[algo]\n",
    "        # Waktu awal training\n",
    "        start_time = time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        # Waktu akhir training\n",
    "        end_time = time.time()\n",
    "\n",
    "        score_train = clf.score(X_train, y_train)\n",
    "\n",
    "        # Waktu awal testing\n",
    "        start_time_test = time.time()\n",
    "\n",
    "        score_test = clf.score(X_test, y_test)\n",
    "\n",
    "        # Waktu akhir testing\n",
    "        end_time_test = time.time()\n",
    "\n",
    "        print(\"%s : Training Score: %s, Testing Score: %s\" % (algo, score_train, score_test))\n",
    "\n",
    "        # Menghitung total waktu training\n",
    "        training_time = end_time - start_time\n",
    "        print(\"Total Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "        # Menghitung total waktu testing\n",
    "        testing_time = end_time_test - start_time_test\n",
    "        print(\"Total Testing Time:\", testing_time, \"seconds\")\n",
    "\n",
    "        results[algo] = (score_train, score_test, training_time, testing_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b5673f0-a1f6-47e9-b96c-7fa41f2eae54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using RandomForest for classification, with 3 features.\n"
     ]
    }
   ],
   "source": [
    "winner = max(results, key=results.get)# Selecting the classifier with good result\n",
    "print(\"Using\", winner, \"for classification, with\",len(features), 'features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ef8ae76-fa49-4856-bd2f-8959f3205b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Dataset 2\n",
    "dataset2 = pd.read_csv(\"C:\\\\Data Raihan\\Perkuliahan Semester 8\\\\SKC\\\\Dataset\\\\APIsecurityAccessbehavoranomalydataset\\supervised_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b0a18ff-e9c0-4ee6-a458-152d4e94ac41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', '_id', 'inter_api_access_duration(sec)',\n",
       "       'api_access_uniqueness', 'sequence_length(count)',\n",
       "       'vsession_duration(min)', 'ip_type', 'num_sessions', 'num_users',\n",
       "       'num_unique_apis', 'source', 'classification'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan nama Kolom yang ada pada dataset 2\n",
    "dataset2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d4dc78e-30e0-4bf8-8683-26f140c3d597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1699 entries, 0 to 1698\n",
      "Data columns (total 12 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Unnamed: 0                      1699 non-null   int64  \n",
      " 1   _id                             1699 non-null   object \n",
      " 2   inter_api_access_duration(sec)  1695 non-null   float64\n",
      " 3   api_access_uniqueness           1695 non-null   float64\n",
      " 4   sequence_length(count)          1699 non-null   float64\n",
      " 5   vsession_duration(min)          1699 non-null   int64  \n",
      " 6   ip_type                         1699 non-null   object \n",
      " 7   num_sessions                    1699 non-null   float64\n",
      " 8   num_users                       1699 non-null   float64\n",
      " 9   num_unique_apis                 1699 non-null   float64\n",
      " 10  source                          1699 non-null   object \n",
      " 11  classification                  1699 non-null   object \n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 159.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan fitur yang ada pada dataset 2\n",
    "dataset2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe513eed-69c9-464e-9619-76c95df0fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection\n",
    "X = dataset2.drop(['Unnamed: 0','_id','ip_type', 'source', 'classification', 'api_access_uniqueness', 'inter_api_access_duration(sec)'], axis=1).select_dtypes(include=['float64', 'int64']).values\n",
    "# Target variable\n",
    "y = dataset2['classification'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b090907a-a6b1-48ec-8971-87e5e0f17fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Fitting and choosing the important variables\n",
    "extratrees = ek.ExtraTreesClassifier().fit(X,y)\n",
    "model = SelectFromModel(extratrees, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "nbfeatures = X_new.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95735da7-689d-4f14-a096-cc9e98240cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ubah label menjadi format numerik\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f27d8ca2-7bf2-494c-a197-3025c5d10830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data (70% - training and 30% - testing)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y ,test_size=0.29, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0673f9f0-6f44-43f9-ab9d-72e2ae9623d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "index = numpy.argsort(extratrees.feature_importances_)[::-1][:nbfeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afef5800-f1bb-40cc-8e51-00075a7c4cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. feature Protocol (0.429146)\n",
      "2. feature Destination Port (0.328881)\n"
     ]
    }
   ],
   "source": [
    "#All the required features\n",
    "for f in range(nbfeatures):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, dataset1.columns[2+index[f]], extratrees.feature_importances_[index[f]]))\n",
    "    features.append(dataset1.columns[2+f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4446f9e8-307a-4421-aef6-050934acafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [(\"Naive Bayes\", GaussianNB()),\n",
    "              (\"DecisionTree\", DecisionTreeClassifier(max_depth=10)),\n",
    "              (\"RandomForest\", ek.RandomForestClassifier(n_estimators=50))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6ccd015-9d99-4909-b9fd-556adf06a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Deep Neural Network (DNN) model\n",
    "model_dnn = Sequential()\n",
    "model_dnn.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "model_dnn.add(Dense(64, activation='relu'))\n",
    "model_dnn.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f01d3915-e32d-45da-bac2-64caf4a91293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train and X_test are your input data arrays\n",
    "X_train_reshaped = np.expand_dims(X_train, axis=-1)\n",
    "X_test_reshaped = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "# Define the Convolutional Neural Network (CNN) model\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Flatten(input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5d045e6-d1a9-49b6-b356-ec34ea8d7968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing which Classifier will give better result\n",
    "model = { \n",
    "    \"DecisionTree\": DecisionTreeClassifier(max_depth=10),\n",
    "    \"RandomForest\": ek.RandomForestClassifier(n_estimators=50),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=0, max_iter=10000),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"MLP\": MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1),\n",
    "    \"Stochastic Gradient Descent\": SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=10000),\n",
    "    \"ADA Boost\": AdaBoostClassifier(n_estimators=100),\n",
    "    \"Stack Ensamble\": StackingClassifier(estimators=estimators, final_estimator=LogisticRegression()),\n",
    "    \"Deep Neural Network\": model_dnn,\n",
    "    \"Convolutional Neural Network\": model_cnn\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f67043a1-0e00-4280-b0b7-576e54d31b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree : Training Score: 1.0, Testing Score: 1.0\n",
      "Total Training Time: 0.0010039806365966797 seconds\n",
      "Total Testing Time: 0.0 seconds\n",
      "RandomForest : Training Score: 1.0, Testing Score: 1.0\n",
      "Total Training Time: 0.04875469207763672 seconds\n",
      "Total Testing Time: 0.0030019283294677734 seconds\n",
      "Logistic Regression : Training Score: 1.0, Testing Score: 1.0\n",
      "Total Training Time: 0.006001472473144531 seconds\n",
      "Total Testing Time: 0.0 seconds\n",
      "Naive Bayes : Training Score: 0.9950248756218906, Testing Score: 1.0\n",
      "Total Training Time: 0.0010004043579101562 seconds\n",
      "Total Testing Time: 0.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP : Training Score: 0.9875621890547264, Testing Score: 0.9939148073022313\n",
      "Total Training Time: 0.3653125762939453 seconds\n",
      "Total Testing Time: 0.0010001659393310547 seconds\n",
      "Stochastic Gradient Descent : Training Score: 1.0, Testing Score: 1.0\n",
      "Total Training Time: 0.0010004043579101562 seconds\n",
      "Total Testing Time: 0.0009996891021728516 seconds\n",
      "ADA Boost : Training Score: 1.0, Testing Score: 1.0\n",
      "Total Training Time: 0.0010006427764892578 seconds\n",
      "Total Testing Time: 0.0 seconds\n",
      "Stack Ensamble : Training Score: 1.0, Testing Score: 1.0\n",
      "Total Training Time: 0.2851376533508301 seconds\n",
      "Total Testing Time: 0.00400090217590332 seconds\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 0s 779us/step - loss: 0.3210 - accuracy: 0.7828\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 762us/step - loss: 0.2293 - accuracy: 0.9569\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 794us/step - loss: 0.1742 - accuracy: 0.9834\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 802us/step - loss: 0.1995 - accuracy: 0.9784\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 807us/step - loss: 0.3350 - accuracy: 0.9577\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 774us/step - loss: 0.5829 - accuracy: 0.9279\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 773us/step - loss: 0.1179 - accuracy: 0.9818\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 773us/step - loss: 0.0457 - accuracy: 0.9967\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 837us/step - loss: 0.4163 - accuracy: 0.9552\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 770us/step - loss: 0.0944 - accuracy: 0.9892\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 789us/step - loss: 0.0444 - accuracy: 0.9950\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 828us/step - loss: 0.2078 - accuracy: 0.9768\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 774us/step - loss: 0.1228 - accuracy: 0.9909\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 769us/step - loss: 0.2332 - accuracy: 0.9809\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 808us/step - loss: 0.2322 - accuracy: 0.9784\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 838us/step - loss: 0.1695 - accuracy: 0.9867\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 833us/step - loss: 0.3118 - accuracy: 0.9710\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 791us/step - loss: 0.0108 - accuracy: 0.9983\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 796us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 812us/step - loss: 0.1537 - accuracy: 0.9884\n",
      "Deep Neural Network : Training Score: 0.9867330193519592, Testing Score: 0.993914783000946\n",
      "Total Training Time: 1.1205766201019287 seconds\n",
      "Total Testing Time: 0.0 seconds\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 0s 650us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 601us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 646us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 636us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 639us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 609us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 606us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 576us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 625us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 625us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 610us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 612us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 590us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 644us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 617us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 626us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 613us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 608us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 618us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 616us/step - loss: 9.9259 - accuracy: 0.6368\n",
      "Convolutional Neural Network : Training Score: 0.6368159055709839, Testing Score: 0.6247464418411255\n",
      "Total Training Time: 0.6523828506469727 seconds\n",
      "Total Testing Time: 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for algo in model:\n",
    "    if algo == \"Deep Neural Network\" or algo == \"Convolutional Neural Network\":\n",
    "        clf = model[algo]\n",
    "        # Waktu awal training\n",
    "        start_time = time.time()\n",
    "        clf.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        clf.fit(X_train, y_train , epochs=20)\n",
    "        # Waktu akhir training\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Evaluate the model\n",
    "        _, score_train = clf.evaluate(X_train, y_train, verbose=0)\n",
    "        _, score_test = clf.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "        # Waktu awal testing\n",
    "        start_time_test = time.time()\n",
    "\n",
    "        # Waktu akhir testing\n",
    "        end_time_test = time.time()\n",
    "\n",
    "        print(\"%s : Training Score: %s, Testing Score: %s\" % (algo, score_train, score_test))\n",
    "\n",
    "        # Menghitung total waktu training\n",
    "        training_time = end_time - start_time\n",
    "        print(\"Total Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "        # Menghitung total waktu testing\n",
    "        testing_time = end_time_test - start_time_test\n",
    "        print(\"Total Testing Time:\", testing_time, \"seconds\")\n",
    "\n",
    "        results[algo] = (score_train, score_test, training_time, testing_time)\n",
    "    else:\n",
    "        clf = model[algo]\n",
    "        # Waktu awal training\n",
    "        start_time = time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        # Waktu akhir training\n",
    "        end_time = time.time()\n",
    "\n",
    "        score_train = clf.score(X_train, y_train)\n",
    "\n",
    "        # Waktu awal testing\n",
    "        start_time_test = time.time()\n",
    "\n",
    "        score_test = clf.score(X_test, y_test)\n",
    "\n",
    "        # Waktu akhir testing\n",
    "        end_time_test = time.time()\n",
    "\n",
    "        print(\"%s : Training Score: %s, Testing Score: %s\" % (algo, score_train, score_test))\n",
    "\n",
    "        # Menghitung total waktu training\n",
    "        training_time = end_time - start_time\n",
    "        print(\"Total Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "        # Menghitung total waktu testing\n",
    "        testing_time = end_time_test - start_time_test\n",
    "        print(\"Total Testing Time:\", testing_time, \"seconds\")\n",
    "\n",
    "        results[algo] = (score_train, score_test, training_time, testing_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8fbb32d-197f-400b-8ee3-4062b94032e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Stack Ensamble for classification, with 2 features.\n"
     ]
    }
   ],
   "source": [
    "winner = max(results, key=results.get)# Selecting the classifier with good result\n",
    "print(\"Using\", winner, \"for classification, with\",len(features), 'features.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
